{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10337673,"sourceType":"datasetVersion","datasetId":6401265},{"sourceId":11796267,"sourceType":"datasetVersion","datasetId":7407516}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup and Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport json\nimport os\nimport uuid\nimport time\nimport requests\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom kaggle_secrets import UserSecretsClient\nfrom datetime import datetime, timedelta\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T14:23:51.088107Z","iopub.execute_input":"2025-05-13T14:23:51.088423Z","iopub.status.idle":"2025-05-13T14:23:52.372711Z","shell.execute_reply.started":"2025-05-13T14:23:51.088400Z","shell.execute_reply":"2025-05-13T14:23:52.371902Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Define Paths and Constants","metadata":{}},{"cell_type":"code","source":"INPUT_DIR = \"/kaggle/input/assignementdataset\"\nCACHE_DIR = \"/kaggle/working/qa_cache/\"\nos.makedirs(CACHE_DIR, exist_ok=True)\n\nuser_secrets = UserSecretsClient()\nOPENROUTER_API_KEY = user_secrets.get_secret(\"OPENROUTER_API_KEY_Mixtral\")\nOPENROUTER_API_URL = \"https://openrouter.ai/api/v1/chat/completions\"\nMODEL_CONFIG = [\"mistralai/mixtral-8x7b-instruct\"]\n\nRATE_LIMIT_RPM = 30\nrequest_timestamps = []\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T14:23:52.374180Z","iopub.execute_input":"2025-05-13T14:23:52.374567Z","iopub.status.idle":"2025-05-13T14:23:52.496780Z","shell.execute_reply.started":"2025-05-13T14:23:52.374546Z","shell.execute_reply":"2025-05-13T14:23:52.496112Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Loading Utilities","metadata":{}},{"cell_type":"code","source":"def load_papers(directory):\n    papers = []\n    for filename in os.listdir(directory):\n        if filename.endswith(\".json\"):\n            with open(os.path.join(directory, filename), 'r') as f:\n                try:\n                    paper = json.load(f)\n                    paper[\"paper_id\"] = filename.replace(\".json\", \"\").replace(\".grobid.tei\", \"\")\n                    papers.append(paper)\n                except json.JSONDecodeError as e:\n                    print(f\"Error loading {filename}: {e}\")\n    return papers\n\ndef load_cached_qa(paper_id):\n    cache_file = os.path.join(CACHE_DIR, f\"{paper_id}.json\")\n    if os.path.exists(cache_file):\n        with open(cache_file, 'r') as f:\n            return json.load(f)\n    return None\n\ndef save_cached_qa(paper_id, qa_pairs):\n    cache_file = os.path.join(CACHE_DIR, f\"{paper_id}.json\")\n    with open(cache_file, 'w') as f:\n        json.dump(qa_pairs, f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T14:23:53.557458Z","iopub.execute_input":"2025-05-13T14:23:53.558489Z","iopub.status.idle":"2025-05-13T14:23:53.565166Z","shell.execute_reply.started":"2025-05-13T14:23:53.558461Z","shell.execute_reply":"2025-05-13T14:23:53.564181Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Input/Output Debugging Helpers","metadata":{}},{"cell_type":"code","source":"def save_paper_input(paper_id, paper_data):\n    input_file = os.path.join(CACHE_DIR, f\"{paper_id}_input.json\")\n    with open(input_file, 'w') as f:\n        json.dump(paper_data, f, indent=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T14:23:53.967570Z","iopub.execute_input":"2025-05-13T14:23:53.967921Z","iopub.status.idle":"2025-05-13T14:23:53.973079Z","shell.execute_reply.started":"2025-05-13T14:23:53.967887Z","shell.execute_reply":"2025-05-13T14:23:53.972226Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Text Cleaning & Extraction Utilities","metadata":{}},{"cell_type":"code","source":"def clean_response(content):\n    content = re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', content)\n    content = content.replace('\\n', ' ').replace('\\r', ' ')\n    content = re.sub(r'\\s+', ' ', content)\n    return content.strip()\n\ndef extract_qa_from_string(content):\n    try:\n        json_match = re.search(r'\\[\\s*\\{.*?\\}\\s*\\]', content, re.DOTALL)\n        if json_match:\n            qa_pairs = json.loads(json_match.group(0))\n            if isinstance(qa_pairs, list):\n                return qa_pairs\n        json_match = re.search(r'\\{.*?\\}', content, re.DOTALL)\n        if json_match:\n            qa_pair = json.loads(json_match.group(0))\n            if isinstance(qa_pair, dict) and \"question\" in qa_pair:\n                return [qa_pair]\n        return []\n    except json.JSONDecodeError:\n        return []\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T14:23:54.307452Z","iopub.execute_input":"2025-05-13T14:23:54.307743Z","iopub.status.idle":"2025-05-13T14:23:54.314179Z","shell.execute_reply.started":"2025-05-13T14:23:54.307722Z","shell.execute_reply":"2025-05-13T14:23:54.313154Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Fallback QA Generator","metadata":{}},{"cell_type":"code","source":"def generate_fallback_qa(title, abstract):\n    abstract = abstract if abstract != \"No abstract\" else f\"The study titled '{title}' investigates medical research topics.\"\n    questions = [\n        f\"What is the primary objective of the study titled '{title}'?\",\n        f\"What key issue does the study titled '{title}' address?\",\n        f\"What is a main finding of the study titled '{title}'?\",\n        f\"What methodology is used in the study titled '{title}'?\",\n        f\"What are the implications of the study titled '{title}'?\"\n    ]\n    qa_pairs = [\n        {\n            \"question\": q,\n            \"answer\": abstract[:200],\n            \"context_location\": \"Abstract\",\n            \"context\": abstract[:100]\n        } for q in questions\n    ]\n    return qa_pairs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T14:23:54.607686Z","iopub.execute_input":"2025-05-13T14:23:54.608008Z","iopub.status.idle":"2025-05-13T14:23:54.614300Z","shell.execute_reply.started":"2025-05-13T14:23:54.607983Z","shell.execute_reply":"2025-05-13T14:23:54.613398Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Rate Limiting Logic","metadata":{}},{"cell_type":"code","source":"def enforce_rate_limit(paper_id):\n    global request_timestamps\n    now = datetime.now()\n    request_timestamps = [t for t in request_timestamps if now - t < timedelta(minutes=1)]\n    if len(request_timestamps) >= RATE_LIMIT_RPM:\n        wait_time = 60 - (now - request_timestamps[0]).total_seconds()\n        if wait_time > 0:\n            print(f\"Rate limit reached for {paper_id}. Waiting for {wait_time:.1f} seconds.\")\n            time.sleep(wait_time)\n        request_timestamps = request_timestamps[1:]\n    request_timestamps.append(now)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T14:23:54.907479Z","iopub.execute_input":"2025-05-13T14:23:54.907740Z","iopub.status.idle":"2025-05-13T14:23:54.913660Z","shell.execute_reply.started":"2025-05-13T14:23:54.907721Z","shell.execute_reply":"2025-05-13T14:23:54.912746Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Core QA Generation Function","metadata":{}},{"cell_type":"code","source":"def generate_qa_with_openrouter(paper, paper_index, max_retries=3, base_delay=60):\n    cached_qa = load_cached_qa(paper[\"paper_id\"])\n    if cached_qa and len(cached_qa) == 5:\n        print(f\"Loaded cached QA for {paper['paper_id']} ({paper_index+1}/43 papers processed)\")\n        return cached_qa\n\n    title = paper.get(\"title\", \"No title\")\n    abstract = paper.get(\"abstract\", \"No abstract\")\n    if \"pdf_parse\" in paper and \"abstract\" in paper[\"pdf_parse\"]:\n        abstract = \" \".join([item[\"text\"] for item in paper[\"pdf_parse\"][\"abstract\"] if isinstance(item, dict) and \"text\" in item])[:500]\n    keywords = \", \".join(paper.get(\"pdf_parse\", {}).get(\"keywords\", []))[:100]\n    sections = paper.get(\"pdf_parse\", {}).get(\"body_text\", [])\n    sections_dict = {item[\"section\"]: item[\"text\"] for item in sections if isinstance(item, dict) and \"section\" in item and \"text\" in item}\n    sections_str = \"\\n\".join([f\"{k}: {v[:400]}\" for k, v in sections_dict.items()])[:1500]\n\n    save_paper_input(paper[\"paper_id\"], {\"title\": title, \"abstract\": abstract, \"keywords\": keywords, \"sections\": sections_dict})\n\n    prompt = f\"\"\"You are an expert in medical research. Reason through the paper’s content to identify key insights, focusing on objectives, methods, findings, limitations, and implications. Generate exactly 5 unique question-answer pairs for the given medical research paper. Each pair MUST include:\n- A unique question related to the paper’s content (e.g., objectives, methods, findings, limitations, implications).\n- An answer based on the paper, derived from your reasoning.\n- The context location (e.g., \"Abstract\", \"Objectives\", \"Search methods\").\n- The context text used for the answer.\n\nPaper Data:\nTitle: {title}\nAbstract: {abstract}\nKeywords: {keywords}\nSections:\n{sections_str}\n\nOutput MUST be a valid JSON array with exactly 5 objects, containing only the specified fields. Return only the JSON array, with no additional text, keys like \"questions\", or invalid characters:\n[\n  {{\n    \"question\": \"Question text\",\n    \"answer\": \"Answer text\",\n    \"context_location\": \"Section name\",\n    \"context\": \"Context text\"\n  }},\n  ...\n]\n\"\"\"\n\n    fallback_prompt = f\"\"\"You are an expert in medical research. Reason through the abstract to identify key insights, focusing on objectives, findings, and implications. Generate exactly 5 unique question-answer pairs for the medical paper titled \"{title}\" with abstract: {abstract}. Each pair must include:\n- A unique question about the paper’s content (e.g., objectives, findings, implications).\n- An answer from the abstract, based on your reasoning.\n- Context location: \"Abstract\".\n- Context text from the abstract.\n\nReturn only a valid JSON array with exactly 5 objects, no extra text or invalid characters:\n[\n  {{\n    \"question\": \"Question text\",\n    \"answer\": \"Answer text\",\n    \"context_location\": \"Abstract\",\n    \"context\": \"Context text\"\n  }},\n  ...\n]\n\"\"\"\n\n    ultra_simple_prompt = f\"\"\"You are an expert in medical research. Reason through the abstract to identify key insights. Generate exactly 5 unique question-answer pairs for the paper titled \"{title}\" with abstract: {abstract}. Each pair must include:\n- A unique question about the paper’s content.\n- An answer from the abstract, based on your reasoning.\n- Context location: \"Abstract\".\n- Context text from the abstract.\n\nReturn: [\n  {{\"question\": \"Question 1\", \"answer\": \"Answer 1\", \"context_location\": \"Abstract\", \"context\": \"Context text\"}},\n  {{\"question\": \"Question 2\", \"answer\": \"Answer 2\", \"context_location\": \"Abstract\", \"context\": \"Context text\"}},\n  {{\"question\": \"Question 3\", \"answer\": \"Answer 3\", \"context_location\": \"Abstract\", \"context\": \"Context text\"}},\n  {{\"question\": \"Question 4\", \"answer\": \"Answer 4\", \"context_location\": \"Abstract\", \"context\": \"Context text\"}},\n  {{\"question\": \"Question 5\", \"answer\": \"Answer 5\", \"context_location\": \"Abstract\", \"context\": \"Context text\"}}\n]\n\"\"\"\n\n    headers = {\n        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n        \"Content-Type\": \"application/json\"\n    }\n    model = MODEL_CONFIG[0]\n    for prompt_version, current_prompt in enumerate([prompt, fallback_prompt, ultra_simple_prompt], 1):\n        payload = {\n            \"model\": model,\n            \"messages\": [{\"role\": \"user\", \"content\": current_prompt}],\n            \"response_format\": {\"type\": \"json_object\"},\n            \"temperature\": 0.7,\n            \"max_tokens\": 5000\n        }\n\n        for attempt in range(max_retries):\n            enforce_rate_limit(paper[\"paper_id\"])\n            try:\n                response = requests.post(OPENROUTER_API_URL, headers=headers, json=payload)\n                response.raise_for_status()\n                response_data = response.json()\n\n                log_file = os.path.join(CACHE_DIR, f\"{paper['paper_id']}_{model.replace('/', '-')}_prompt{prompt_version}_attempt{attempt+1}_raw_response.json\")\n                with open(log_file, 'w') as f:\n                    json.dump({\n                        \"status_code\": response.status_code,\n                        \"headers\": dict(response.headers),\n                        \"body\": response_data\n                    }, f, indent=2)\n\n                content = response_data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n                if not content:\n                    print(f\"Empty content in response for {paper['paper_id']} with {model}, prompt {prompt_version}, attempt {attempt+1}, status {response.status_code} ({paper_index+1}/43 papers processed)\")\n                    continue\n\n                usage = response_data.get(\"usage\", {})\n                print(f\"Tokens for {paper['paper_id']} with {model}: prompt={usage.get('prompt_tokens', 0)}, completion={usage.get('completion_tokens', 0)} ({paper_index+1}/43 papers processed)\")\n\n                content = clean_response(content)\n                qa_pairs = json.loads(content)\n                if not isinstance(qa_pairs, list):\n                    if isinstance(qa_pairs, dict) and \"questions\" in qa_pairs:\n                        qa_pairs = extract_qa_from_string(qa_pairs.get(\"questions\", \"\"))\n                    else:\n                        qa_pairs = extract_qa_from_string(content)\n\n                if not isinstance(qa_pairs, list) or len(qa_pairs) == 0:\n                    print(f\"Invalid QA pairs for {paper['paper_id']} with {model}, prompt {prompt_version}, attempt {attempt+1}: {qa_pairs} ({paper_index+1}/43 papers processed)\")\n                    continue\n\n                valid_qa = [\n                    qa for qa in qa_pairs\n                    if isinstance(qa, dict) and all(k in qa for k in [\"question\", \"answer\", \"context_location\", \"context\"])\n                ]\n                if len(valid_qa) != 5:\n                    print(f\"Expected 5 QA pairs, got {len(valid_qa)} for {paper['paper_id']} with {model}, prompt {prompt_version}, attempt {attempt+1} ({paper_index+1}/43 papers processed)\")\n                    continue\n\n                seen_questions = set()\n                unique_qa = []\n                for qa in valid_qa:\n                    if qa[\"question\"] not in seen_questions:\n                        seen_questions.add(qa[\"question\"])\n                        unique_qa.append(qa)\n\n                if len(unique_qa) != 5:\n                    print(f\"Expected 5 unique QA pairs, got {len(unique_qa)} for {paper['paper_id']} with {model}, prompt {prompt_version}, attempt {attempt+1} ({paper_index+1}/43 papers processed)\")\n                    continue\n\n                save_cached_qa(paper[\"paper_id\"], unique_qa)\n                print(f\"Success with {model}, prompt {prompt_version} for {paper['paper_id']}: 5 QA pairs ({paper_index+1}/43 papers processed)\")\n                return unique_qa\n            except requests.exceptions.RequestException as e:\n                status_code = response.status_code if 'response' in locals() else None\n                if status_code == 429 and attempt < max_retries - 1:\n                    wait_time = base_delay * (2 ** attempt)\n                    retry_after = response.headers.get(\"Retry-After\")\n                    if retry_after:\n                        wait_time = max(wait_time, int(retry_after))\n                    print(f\"429 rate limit exceeded for {paper['paper_id']} with {model}, prompt {prompt_version}, attempt {attempt+1}. Waiting for {wait_time} seconds at {datetime.now().strftime('%H:%M:%S')} ({paper_index+1}/43 papers processed)\")\n                    time.sleep(wait_time)\n                else:\n                    print(f\"Request error for {paper['paper_id']} with {model}, prompt {prompt_version}, attempt {attempt+1}, status {status_code}: {e} ({paper_index+1}/43 papers processed)\")\n                    continue\n            except json.JSONDecodeError as e:\n                print(f\"JSON error for {paper['paper_id']} with {model}, prompt {prompt_version}, attempt {attempt+1}: {e} ({paper_index+1}/43 papers processed)\")\n                continue\n            time.sleep(2)\n\n    print(f\"All attempts failed for {paper['paper_id']} ({paper_index+1}/43 papers processed)\")\n    qa_pairs = generate_fallback_qa(title, abstract)\n    save_cached_qa(paper[\"paper_id\"], qa_pairs)\n    print(f\"Generated 5 fallback QA pairs for {paper['paper_id']} ({paper_index+1}/43 papers processed)\")\n    return qa_pairs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T14:23:59.593651Z","iopub.execute_input":"2025-05-13T14:23:59.593988Z","iopub.status.idle":"2025-05-13T14:23:59.617088Z","shell.execute_reply.started":"2025-05-13T14:23:59.593961Z","shell.execute_reply":"2025-05-13T14:23:59.616216Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Execution Loop","metadata":{}},{"cell_type":"code","source":"def process_papers(batch_size=15):\n    papers = load_papers(INPUT_DIR)\n    print(f\"Loaded {len(papers)} papers\")\n    \n    all_qa_pairs = []\n    skipped_papers = []\n    for i in range(0, len(papers), batch_size):\n        batch = papers[i:i + batch_size]\n        print(f\"Processing batch {i//batch_size + 1}: {len(batch)} papers\")\n        for j, paper in enumerate(batch):\n            paper_index = i + j\n            print(f\"Processing {paper['paper_id']} ({paper_index+1}/43 papers processed)\")\n            qa_pairs = generate_qa_with_openrouter(paper, paper_index)\n            if len(qa_pairs) != 5:\n                print(f\"Failed to generate exactly 5 QA pairs for {paper['paper_id']} ({paper_index+1}/43 papers processed)\")\n                skipped_papers.append(paper[\"paper_id\"])\n                continue\n            for qa in qa_pairs:\n                all_qa_pairs.append({\n                    \"question_id\": str(uuid.uuid4()),\n                    \"question\": qa[\"question\"],\n                    \"answer\": qa[\"answer\"],\n                    \"context_location\": qa[\"context_location\"],\n                    \"context\": qa[\"context\"],\n                    \"paper\": paper[\"paper_id\"]\n                })\n            time.sleep(5)  # Reduced per-paper delay\n        # Batch delay\n        if i + batch_size < len(papers):\n            print(f\"Batch delay for 60 seconds at {datetime.now().strftime('%H:%M:%S')}\")\n            time.sleep(60)\n    \n    # Log skipped papers\n    if skipped_papers:\n        with open(os.path.join(CACHE_DIR, \"skipped_papers.txt\"), \"w\") as f:\n            f.write(\"\\n\".join(skipped_papers))\n        print(f\"Skipped papers: {skipped_papers}\")\n    \n    train_df = pd.DataFrame(all_qa_pairs)\n    paper_counts = train_df[\"paper\"].value_counts()\n    valid_papers = paper_counts[paper_counts == 5].index  # Exactly 5 QA pairs per paper\n    train_df = train_df[train_df[\"paper\"].isin(valid_papers)]\n    \n    if len(train_df) == 0:\n        print(\"No papers with exactly 5 QA pairs. Exiting.\")\n        return pd.DataFrame(), pd.DataFrame()\n    \n    try:\n        train_data, test_data = train_test_split(\n            train_df,\n            test_size=0.2,\n            random_state=42,\n            stratify=train_df[\"paper\"]\n        )\n    except ValueError as e:\n        print(f\"Stratification failed: {e}. Splitting without stratification.\")\n        train_data, test_data = train_test_split(\n            train_df,\n            test_size=0.2,\n            random_state=42\n        )\n    \n    test_df = pd.DataFrame({\n        \"question_id\": test_data[\"question_id\"],\n        \"question\": test_data[\"question\"],\n        \"paper\": test_data[\"paper\"],\n        \"answer\": test_data[\"answer\"],\n        \"context_location\": test_data[\"context_location\"],\n        \"context\": test_data[\"context\"]\n    })\n    \n    train_df.to_csv(\"/kaggle/working/train_data.csv\", index=False)\n    test_df.to_csv(\"/kaggle/working/test_data.csv\", index=False)\n    \n    print(f\"Completed processing {len(papers)} papers\")\n    return train_df, test_df\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T14:24:00.156779Z","iopub.execute_input":"2025-05-13T14:24:00.157123Z","iopub.status.idle":"2025-05-13T14:24:00.167896Z","shell.execute_reply.started":"2025-05-13T14:24:00.157099Z","shell.execute_reply":"2025-05-13T14:24:00.167151Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Main Exceution","metadata":{}},{"cell_type":"code","source":"# Execute\nif __name__ == \"__main__\":\n    train_df, test_df = process_papers()\n    print(\"Train DataFrame shape:\", train_df.shape)\n    print(\"Test DataFrame shape:\", test_df.shape)\n    print(\"Test columns:\", test_df.columns.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T14:24:02.461575Z","iopub.execute_input":"2025-05-13T14:24:02.461889Z","iopub.status.idle":"2025-05-13T14:36:09.112398Z","shell.execute_reply.started":"2025-05-13T14:24:02.461846Z","shell.execute_reply":"2025-05-13T14:36:09.111642Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/assignmentqa/train_data(2).csv\")\ntrain","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T14:42:15.463108Z","iopub.execute_input":"2025-05-13T14:42:15.463421Z","iopub.status.idle":"2025-05-13T14:42:15.511520Z","shell.execute_reply.started":"2025-05-13T14:42:15.463397Z","shell.execute_reply":"2025-05-13T14:42:15.510635Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test=pd.read_csv(\"/kaggle/input/assignmentqa/test_data(2).csv\")\ntest","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T14:43:25.104078Z","iopub.execute_input":"2025-05-13T14:43:25.104899Z","iopub.status.idle":"2025-05-13T14:43:25.129942Z","shell.execute_reply.started":"2025-05-13T14:43:25.104846Z","shell.execute_reply":"2025-05-13T14:43:25.129121Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null}]}