{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10337673,"sourceType":"datasetVersion","datasetId":6401265},{"sourceId":11796267,"sourceType":"datasetVersion","datasetId":7407516},{"sourceId":5112,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":3900,"modelId":1902},{"sourceId":84013,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":70561,"modelId":95613}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Setup & Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport glob\nimport json\nimport numpy as np\nimport torch\n\nfrom sentence_transformers import SentenceTransformer\nimport faiss\nfrom tqdm import tqdm\nimport requests\nfrom sklearn.model_selection import train_test_split\nfrom pathlib import Path\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" # 2. OpenRouter API Configuration\n","metadata":{}},{"cell_type":"code","source":"\nOPENROUTER_API_KEY = \"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\"\nOPENROUTER_API_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Load and Process Papers","metadata":{}},{"cell_type":"code","source":"\ndef load_papers(directory=\"/kaggle/input/assignementdataset\"):\n    json_files = [f for f in Path(directory).glob(\"*.json\") if f.is_file()]\n    all_data = []\n    for file in tqdm(json_files, desc=\"Loading JSON files\"):\n        with open(file, 'r') as f:\n            try:\n                doc = json.load(f)\n                text = extract_text_from_json(doc)\n                all_data.append({\"file\": file.name, \"text\": text})\n            except json.JSONDecodeError as e:\n                print(f\"Error parsing {file.name}: {e}\")\n                continue\n    return pd.DataFrame(all_data)\n\ndef extract_text_from_json(doc):\n    if \"body_text\" in doc:\n        return \" \".join([section[\"text\"] for section in doc[\"body_text\"] if \"text\" in section])\n    elif isinstance(doc, dict):\n        return \" \".join(str(v) for v in doc.values() if isinstance(v, str))\n    return \"\"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Split Dataset Into Train and Test","metadata":{}},{"cell_type":"code","source":"\ndef split_dataset(df, test_size=0.2, random_state=42):\n    train_df, test_df = train_test_split(df, test_size=test_size, random_state=random_state)\n    return train_df.reset_index(drop=True), test_df.reset_index(drop=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Build Sentence Transformer Retriever","metadata":{}},{"cell_type":"code","source":"\ndef build_retriever(df, model_name=\"all-MiniLM-L6-v2\"):\n    model = SentenceTransformer(model_name, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    texts = df[\"text\"].fillna(\"\").tolist()\n    embeddings = model.encode(texts, show_progress_bar=True, batch_size=16)\n    index = faiss.IndexFlatL2(embeddings.shape[1])\n    index.add(embeddings.astype(np.float32))\n    return model, index\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. Retrieval and Answer Generation","metadata":{}},{"cell_type":"code","source":"\ndef retrieve_and_answer(question, df, model, index, max_context_length=2000):\n    question_embedding = model.encode([question])[0]\n    distances, indices = index.search(np.array([question_embedding]).astype(np.float32), k=1)\n    paper_idx = indices[0][0]\n    relevant_paper = df.iloc[paper_idx]\n    context = relevant_paper[\"text\"][:max_context_length]\n\n    # Enhanced prompt for better reasoning\n    prompt = f\"\"\"\nYou are a highly capable AI assistant trained in reproductive medicine literature. Your task is to reason carefully and answer the question based on the provided academic context. Think step-by-step if needed.\n\n### Instructions:\n- Read the context below.\n- Infer and construct the most accurate answer possible, even if it's not word-for-word.\n- Then identify and copy the exact sentence or paragraph that supports your answer.\n- Finally, specify its location (e.g., sentence number or paragraph number).\n\n### Format:\nAnswer: <your well-reasoned answer>\nContext Snippet: <exact supporting sentence or paragraph from the context>\nLocation: <where the snippet is found â€” e.g., \"2nd sentence\", \"3rd paragraph\", etc.>\n\n### Input:\nQuestion: {question}\nContext: {context}\n\"\"\"\n\n    headers = {\n        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n        \"Content-Type\": \"application/json\"\n    }\n    payload = {\n        \"model\": \"mistralai/mixtral-8x7b-instruct\",\n        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n        \"temperature\": 0.2,\n        \"max_tokens\": 500\n    }\n\n    try:\n        response = requests.post(OPENROUTER_API_URL, headers=headers, json=payload)\n        response.raise_for_status()\n        response_data = response.json()\n        response_text = response_data[\"choices\"][0][\"message\"][\"content\"]\n    except Exception as e:\n        print(f\"API request failed: {e}\")\n        return {\n            \"paper_title\": relevant_paper[\"file\"],\n            \"answer\": \"Error\",\n            \"context_snippet\": \"Error\",\n            \"location\": \"Error\",\n            \"paper_idx\": paper_idx\n        }\n\n    # Parse the LLM output\n    answer = context_snippet = location = \"Not found\"\n    for line in response_text.split(\"\\n\"):\n        if line.strip().lower().startswith(\"answer:\"):\n            answer = line.split(\":\", 1)[1].strip()\n        elif line.strip().lower().startswith(\"context snippet:\"):\n            context_snippet = line.split(\":\", 1)[1].strip()\n        elif line.strip().lower().startswith(\"location:\"):\n            location = line.split(\":\", 1)[1].strip()\n\n    return {\n        \"paper_title\": relevant_paper[\"file\"],\n        \"answer\": answer,\n        \"context_snippet\": context_snippet,\n        \"location\": location,\n        \"paper_idx\": paper_idx\n    }\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7 Evaluate the Retrieval","metadata":{}},{"cell_type":"code","source":"\ndef evaluate_retrieval(test_df, model, index, question, expected_idx=None):\n    result = retrieve_and_answer(question, test_df, model, index)\n    print(\"\\nEvaluation Results:\")\n    print(f\"Question: {question}\")\n    print(f\"Retrieved Paper: {result['paper_title']} (Index: {result['paper_idx']})\")\n    print(f\"Answer: {result['answer']}\")\n    print(f\"Context Snippet: {result['context_snippet']}\")\n    print(f\"Location: {result['location']}\")\n    if expected_idx is not None:\n        print(f\"Correct Retrieval: {result['paper_idx'] == expected_idx}\")\n    return result\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 8. Main Execution - Loading Data and Running the Model","metadata":{}},{"cell_type":"code","source":"\nif __name__ == \"__main__\":\n    print(\"Loading papers...\")\n    df = load_papers()\n    print(f\"Loaded {len(df)} papers.\")\n\n    print(\"Splitting dataset...\")\n    train_df, test_df = split_dataset(df, test_size=0.2)\n    print(f\"Training set: {len(train_df)} papers\")\n    print(f\"Test set: {len(test_df)} papers\")\n\n    print(\"Building retriever...\")\n    model, index = build_retriever(train_df)\n\n    custom_question = input(\"\\nEnter your question: \")\n    print(\"Processing question...\")\n\n    result = retrieve_and_answer(custom_question, train_df, model, index)\n\n    print(\"\\nResults:\")\n    print(f\"Most Relevant Paper: {result['paper_title']}\")\n    print(f\"Answer: {result['answer']}\")\n    print(f\"Context Snippet: {result['context_snippet']}\")\n    print(f\"Location: {result['location']}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 9. Input and Running the Model","metadata":{}},{"cell_type":"code","source":"\ncustom_question = \"What is the effect of environmental factors on fertility rates?\"\nresult = retrieve_and_answer(custom_question, train_df, model, index)\n\n# Output results\nprint(f\"Most Relevant Paper: {result['paper_title']}\")\nprint(f\"Answer: {result['answer']}\")\nprint(f\"Context Snippet: {result['context_snippet']}\")\nprint(f\"Location: {result['location']}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}